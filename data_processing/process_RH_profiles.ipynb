{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f01b49ac-3238-48d0-be6b-28b08c599209",
   "metadata": {},
   "source": [
    "This notebook aims at processing the data used to plot the relative humidity (RH) profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8eac4ab3-f5cd-4d0f-9c51-405d12936236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake\n",
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import dask.array as da\n",
    "import pandas as pd\n",
    "import glob\n",
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940dfe3d-d437-458d-924d-7b4ae5dacbf5",
   "metadata": {},
   "source": [
    "## Get the RH data and the clouds data processed in the code process_LW_BCO_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b41ad9ab-a8ae-4214-a4f6-aa31f10ce37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RH = xr.open_dataset('./../data/RH.nc')['rh'] #this contains relative humidity data from Jan-Feb 2020  (EUREC4A period)\n",
    "\n",
    "start_time = np.datetime64('2020-01-12T00:00:00')\n",
    "end_time   = np.datetime64('2020-02-28T23:00:00')\n",
    "windspeed = xr.open_dataset('./../data/windspeed_eurec4a.nc')['wind_speed']\n",
    "windspeed_avg = windspeed.sel(range = 1000, method = 'nearest').mean(dim = 'time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ae60075-de3a-420c-9b72-e446cff46410",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We load the cloud borders array that has been processed in the code \"process_LW_BCO_data.ipynb\"\n",
    "clouds = np.loadtxt('./../data/processed_data/cloud_borders_eurec4a.txt', delimiter=',', dtype='object') \n",
    "clouds[:, 0] = np.array(clouds[:, 0], dtype='datetime64[s]')\n",
    "clouds[:, 1] = np.array(clouds[:, 1], dtype='datetime64[s]')\n",
    "clouds[:, 2] = np.array(clouds[:, 2], dtype='float64')\n",
    "clouds[:, 3] = np.array(clouds[:, 3], dtype='float64')\n",
    "clouds[:, 4] = np.array(clouds[:, 4], dtype='float64')\n",
    "clouds[:, 5] = np.array(clouds[:, 5], dtype='float64')\n",
    "\n",
    "#Since MR data is only available during Januray February (EUREC4A period), we restric our clouds during that time\n",
    "#clouds_time = clouds[(clouds[:, 0] >= start_time) & (clouds[:, 0] <= end_time)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8661756-279a-4a52-a116-2ca2fa1bcaf5",
   "metadata": {},
   "source": [
    "## anomalies 1d profiles at the specific heights: SCL, CL, TCL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4de6273-32ce-4a86-a88c-78113c1e33fd",
   "metadata": {},
   "source": [
    "The aim is to prepares the data to plot profiles of RH anomaly as a function of distances for the three defined heights: SCL, CL, TCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be71c173-b604-4224-b7f0-4eca8155f48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function puts NaN where the are clouds to avoid contamination of the profiles by clouds, and be sure that we only look at sourrounding of clouds.\n",
    "def mask_clouds(RH, clouds):\n",
    "    for cloud in clouds:\n",
    "        start_time = np.datetime64(cloud[0])\n",
    "        end_time = np.datetime64(cloud[1])\n",
    "        \n",
    "\n",
    "        # Mask the values in MR for the given time range\n",
    "        RH = RH.where(~((RH.time >= start_time) & (RH.time <= end_time)), np.nan)\n",
    "        \n",
    "    return RH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78beaced-293a-4150-a8c7-feeda2144549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We do a pre-selection of clouds such that it runs faster. We take clouds that are longer than 40m and with a cloud base below 1500 (to stay in the boundary layer)\n",
    "clouds = clouds_time[(clouds_time[:,2] >= 40) & (clouds_time[:,3] <= 1500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04392aff-642f-48bb-ae30-9062bca2624f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27min 49s, sys: 7.04 s, total: 27min 56s\n",
      "Wall time: 28min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "masked_RH = mask_clouds(RH, clouds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01675d4c-8858-4a63-be38-dabcea0bb911",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_RH.to_netcdf('./../data/processed_data/1d_anomalies/masked_RH.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce36897a-6abc-45f7-b47d-93ade449c20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_RH = xr.open_dataset('./../data/processed_data/1d_anomalies/masked_RH.nc')['rh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73046d08-d0c2-48be-be01-81545ebd3ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definition of shallow and deep clouds:\n",
    "clouds_shallow = clouds[((clouds[:,4] - clouds[:,3]) >= 100) & ((clouds[:,4] - clouds[:,3]) <= 600)]\n",
    "clouds_deep = clouds[((clouds[:,4] - clouds[:,3]) >= 400) & ((clouds[:,4] - clouds[:,3]) <= 2500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5975d2e-1614-43cc-8bb7-ee375a790591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used later to interpolate data where there are gaps.\n",
    "def interpolate_time(RH, start_time):\n",
    "    RH['time'] = np.round(np.abs((RH.time - start_time) / np.timedelta64(1, 's')))\n",
    "    RH_filled = RH.interpolate_na(dim='alt', method='linear', limit=None)\n",
    "\n",
    "    # Interpolate along the time and altitude dimension\n",
    "    new_time = np.arange(0, 60*60, 4)\n",
    "    RH_interpolated = RH_filled.interp(time=new_time)\n",
    "    return RH_interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91e37281-39d4-4520-898f-7bad0977e09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def profiles_1_d_alt(RH, clouds):\n",
    "    \"\"\"\n",
    "    This function goes through all clouds. I first computes the RH anomaly at each level It separates data into 6 boxes: first up/downwind, and then it takes the \n",
    "    subcloud layer (200m below), the cloud layer and  the topcloud layer (200m above).\n",
    "    Then it concatenates the data by including info on the cloud (length, base, top,...)\n",
    "\n",
    "\n",
    "    inputs:\n",
    "    - RH\n",
    "    - clouds\n",
    "\n",
    "    Outputs:\n",
    "    \n",
    "    - 6 xarrays (before, after; and bottom, mid, top) with the profiles of RH anomalies as a function of distance to the cloud\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    delta_time = np.timedelta64(60, 'm')  # time we look before and after the cloud \n",
    "\n",
    "    #define the different array where we will store the anomaly profiles of RH\n",
    "    RH_before_bottom_arrays = [] \n",
    "    RH_after_bottom_arrays = [] \n",
    "    RH_before_mid_arrays = [] \n",
    "    RH_after_mid_arrays = [] \n",
    "    RH_before_top_arrays = [] \n",
    "    RH_after_top_arrays = [] \n",
    "    \n",
    "    cloud_length = []\n",
    "    cloud_bottom = []\n",
    "    cloud_top = []\n",
    "    cloud_mid = []\n",
    "    cloud_depth = []\n",
    "\n",
    "    #Iterate over all the clouds to compute their anomly profile at the three levels\n",
    "    for cloud_index, cloud_times in enumerate(clouds):\n",
    "        \n",
    "        start_time = np.datetime64(cloud_times[0])\n",
    "        end_time = np.datetime64(cloud_times[1])\n",
    "        cloud_bottom_i = cloud_times[3]\n",
    "        cloud_top_i = cloud_times[4]\n",
    "        cloud_mid_i = cloud_times[5]\n",
    "        cloud_depth_i = cloud_top_i - cloud_mid_i\n",
    "        timedelta_before = start_time - delta_time\n",
    "        timedelta_after = end_time + delta_time\n",
    "        \n",
    "        # Create the anomaly (subtracting the mean)\n",
    "        RH_cloud = RH.sel(time=slice(timedelta_before, timedelta_after))\n",
    "        RH_anomaly = RH_cloud - RH_cloud.mean(dim='time')\n",
    "\n",
    "        # For each cloud, we separate into 6: up/down, bottom, mid, top, and then fill the arrays with numbers over time that are means over \n",
    "        # the altitude of the box:\n",
    "        # before the cloud/downwind\n",
    "        RH_before = RH_anomaly.sel(time=slice(timedelta_before, start_time))\n",
    "        RH_before_bottom = RH_before.sel(alt=slice(cloud_bottom_i - 200, cloud_bottom_i))\n",
    "        RH_before_bottom = interpolate_time(RH_before_bottom, start_time)\n",
    "        RH_before_bottom = RH_before_bottom.mean(dim='alt', skipna=True)\n",
    "        \n",
    "        RH_before_mid = RH_before.sel(alt=slice(cloud_bottom_i, cloud_top_i))\n",
    "        RH_before_mid = interpolate_time(RH_before_mid, start_time)\n",
    "        RH_before_mid = RH_before_mid.mean(dim='alt', skipna=True)\n",
    "        \n",
    "        RH_before_top = RH_before.sel(alt=slice(cloud_top_i, cloud_top_i + 200))\n",
    "        RH_before_top = interpolate_time(RH_before_top, start_time)\n",
    "        RH_before_top = RH_before_top.mean(dim='alt', skipna=True)\n",
    "\n",
    "        RH_before_bottom_arrays.append(lw_down_clouds_dist_approx(RH_before_bottom, windspeed_avg))\n",
    "        RH_before_mid_arrays.append(lw_down_clouds_dist_approx(RH_before_mid, windspeed_avg))\n",
    "        RH_before_top_arrays.append(lw_down_clouds_dist_approx(RH_before_top, windspeed_avg))\n",
    "\n",
    "        # upwind\n",
    "        RH_after = RH_anomaly.sel(time=slice(end_time, timedelta_after))\n",
    "        \n",
    "        RH_after_bottom = RH_after.sel(alt=slice(cloud_bottom_i - 200, cloud_bottom_i))\n",
    "        RH_after_bottom = interpolate_time(RH_after_bottom, start_time)\n",
    "        RH_after_bottom = RH_after_bottom.mean(dim='alt', skipna=True)\n",
    "    \n",
    "        RH_after_mid = RH_after.sel(alt=slice(cloud_bottom_i, cloud_top_i))\n",
    "        RH_after_mid = interpolate_time(RH_after_mid, start_time)\n",
    "        RH_after_mid = RH_after_mid.mean(dim='alt', skipna=True)\n",
    "        \n",
    "        RH_after_top = RH_after.sel(alt=slice(cloud_top_i, cloud_top_i + 200))\n",
    "        RH_after_top = interpolate_time(RH_after_top, start_time)\n",
    "        RH_after_top = RH_after_top.mean(dim='alt', skipna=True)\n",
    "\n",
    "        RH_after_bottom_arrays.append(lw_down_clouds_dist_approx(RH_after_bottom, windspeed_avg))\n",
    "        RH_after_mid_arrays.append(lw_down_clouds_dist_approx(RH_after_mid, windspeed_avg))\n",
    "        RH_after_top_arrays.append(lw_down_clouds_dist_approx(RH_after_top, windspeed_avg))\n",
    "\n",
    "        cloud_length.append(clouds[cloud_index][2])\n",
    "        cloud_bottom.append(clouds[cloud_index][3])\n",
    "        cloud_top.append(clouds[cloud_index][4])\n",
    "        cloud_mid.append(clouds[cloud_index][5])\n",
    "        cloud_depth.append(cloud_depth_i)\n",
    "            \n",
    "    #create a new function that combines all the arrays together and includes the informations on the clouds\n",
    "    def create_combined_xarray(before_arrays, after_arrays):\n",
    "        combined_before = xr.concat(before_arrays, dim='cloud')\n",
    "        combined_before.coords['cloud_length'] = ('cloud', cloud_length)\n",
    "        combined_before.coords['cloud_bottom'] = ('cloud', cloud_bottom)\n",
    "        combined_before.coords['cloud_mid'] = ('cloud', cloud_mid)\n",
    "        combined_before.coords['cloud_top'] = ('cloud', cloud_top)\n",
    "        combined_before.coords['cloud_depth'] = ('cloud', cloud_depth)\n",
    "    \n",
    "        combined_after = xr.concat(after_arrays, dim='cloud')\n",
    "        combined_after.coords['cloud_length'] = ('cloud', cloud_length)\n",
    "        combined_after.coords['cloud_bottom'] = ('cloud', cloud_bottom)\n",
    "        combined_after.coords['cloud_mid'] = ('cloud', cloud_mid)\n",
    "        combined_after.coords['cloud_top'] = ('cloud', cloud_top)\n",
    "        combined_after.coords['cloud_depth'] = ('cloud', cloud_depth)\n",
    "    \n",
    "        return combined_before, combined_after\n",
    "    \n",
    "    RH_combined_before_bottom, RH_combined_after_bottom = create_combined_xarray(RH_before_bottom_arrays, RH_after_bottom_arrays)\n",
    "    RH_combined_before_mid, RH_combined_after_mid = create_combined_xarray(RH_before_mid_arrays, RH_after_mid_arrays)\n",
    "    RH_combined_before_top, RH_combined_after_top = create_combined_xarray(RH_before_top_arrays, RH_after_top_arrays)\n",
    "    \n",
    "    return RH_combined_before_bottom, RH_combined_before_mid, RH_combined_before_top, RH_combined_after_bottom, RH_combined_after_mid, RH_combined_after_top\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74332451-8f82-4beb-9503-bfac62cea6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function goes through all clouds. I first computes the RH anomaly at each level It separates data into 6 boxes: first up/downwind, and then it takes the \n",
    "subcloud layer (200m below), the cloud layer and  the topcloud layer (200m above).\n",
    "Then it concatenates the data by including info on the cloud (length, base, top,...)\n",
    "\n",
    "Returns 6 xarrays (before,after; and bottom,mid,top)\n",
    "\"\"\"\n",
    "def profiles_1_d_alt(MR, clouds):\n",
    "    delta_time = np.timedelta64(60, 'm') #time we look before and after the cloud \n",
    "    \n",
    "    MR_before_bottom_arrays = [] \n",
    "    MR_after_bottom_arrays = [] \n",
    "    MR_before_mid_arrays = [] \n",
    "    MR_after_mid_arrays = [] \n",
    "    MR_before_top_arrays = [] \n",
    "    MR_after_top_arrays = [] \n",
    "    \n",
    "    cloud_length = []\n",
    "    cloud_bottom = []\n",
    "    cloud_top = []\n",
    "    cloud_mid = []\n",
    "    cloud_depth = []\n",
    "    \n",
    "    for cloud_index, cloud_times in enumerate(clouds):\n",
    "        \n",
    "        start_time = np.datetime64(cloud_times[0])\n",
    "        end_time = np.datetime64(cloud_times[1])\n",
    "        cloud_bottom_i = cloud_times[3]\n",
    "        cloud_top_i = cloud_times[4]\n",
    "        cloud_mid_i = cloud_times[5]\n",
    "        cloud_depth_i = cloud_top_i - cloud_mid_i\n",
    "        timedelta_before = start_time - delta_time\n",
    "        timedelta_after = end_time + delta_time\n",
    "\n",
    "        #create the anomaly (subtracting the mean)\n",
    "        MR_cloud = MR.sel(time = slice(timedelta_before, timedelta_after))\n",
    "        MR_anomaly = MR_cloud - MR_cloud.mean(dim='time')\n",
    "\n",
    "        #for each cloud, we separate into 6: up/down, bottom, mid, top, and then fill the arrays with numbers over time that are means over \n",
    "        #the altitude of the box:\n",
    "        #before the cloud/downwind\n",
    "        MR_before = MR_anomaly.sel(time = slice(timedelta_before, start_time))\n",
    "        \n",
    "        MR_before_bottom = MR_before.sel(alt = slice(cloud_bottom_i - 200, cloud_bottom_i))\n",
    "        MR_before_bottom = interpolate_time(MR_before_bottom,start_time)\n",
    "        MR_before_bottom = MR_before_bottom.mean(dim='alt', skipna = True)\n",
    "        \n",
    "        MR_before_mid = MR_before.sel(alt = slice(cloud_bottom_i , cloud_top_i))\n",
    "        MR_before_mid = interpolate_time(MR_before_mid,start_time)\n",
    "        MR_before_mid = MR_before_mid.mean(dim='alt', skipna = True)\n",
    "        \n",
    "        MR_before_top = MR_before.sel(alt = slice(cloud_top_i, cloud_top_i + 200))\n",
    "        MR_before_top = interpolate_time(MR_before_top,start_time)\n",
    "        MR_before_top = MR_before_top.mean(dim='alt', skipna = True)\n",
    "\n",
    "\n",
    "        MR_before_bottom_arrays.append(lw_down_clouds_dist_approx(MR_before_bottom, windspeed_avg))\n",
    "        MR_before_mid_arrays.append(lw_down_clouds_dist_approx(MR_before_mid, windspeed_avg))\n",
    "        MR_before_top_arrays.append(lw_down_clouds_dist_approx(MR_before_top, windspeed_avg))\n",
    "\n",
    "\n",
    "        #upwind\n",
    "        MR_after = MR_anomaly.sel(time = slice(end_time, timedelta_after))\n",
    "        \n",
    "        MR_after_bottom = MR_after.sel(alt = slice(cloud_bottom_i - 200, cloud_bottom_i))\n",
    "        MR_after_bottom = interpolate_time(MR_after_bottom,start_time)\n",
    "        MR_after_bottom = MR_after_bottom.mean(dim='alt', skipna = True)\n",
    "        \n",
    "        MR_after_mid = MR_after.sel(alt = slice(cloud_bottom_i , cloud_top_i))\n",
    "        MR_after_mid = interpolate_time(MR_after_mid,start_time)\n",
    "        MR_after_mid = MR_after_mid.mean(dim='alt', skipna = True)\n",
    "        \n",
    "        MR_after_top = MR_after.sel(alt = slice(cloud_top_i, cloud_top_i + 200))\n",
    "        MR_after_top = interpolate_time(MR_after_top,start_time)\n",
    "        MR_after_top = MR_after_top.mean(dim='alt', skipna = True)\n",
    "\n",
    "\n",
    "        MR_after_bottom_arrays.append(lw_down_clouds_dist_approx(MR_after_bottom, windspeed_avg))\n",
    "        MR_after_mid_arrays.append(lw_down_clouds_dist_approx(MR_after_mid, windspeed_avg))\n",
    "        MR_after_top_arrays.append(lw_down_clouds_dist_approx(MR_after_top, windspeed_avg))\n",
    "\n",
    "        cloud_length.append(clouds[cloud_index][2])\n",
    "        cloud_bottom.append(clouds[cloud_index][3])\n",
    "        cloud_top.append(clouds[cloud_index][4])\n",
    "        cloud_mid.append(clouds[cloud_index][5])\n",
    "        cloud_depth.append(cloud_depth_i)\n",
    "\n",
    "\n",
    "        def create_combined_xarray(before_arrays, after_arrays):\n",
    "                combined_before = xr.concat(before_arrays, dim='cloud')\n",
    "                combined_before.coords['cloud_length'] = ('cloud', cloud_length)\n",
    "                combined_before.coords['cloud_bottom'] = ('cloud', cloud_bottom)\n",
    "                combined_before.coords['cloud_mid'] = ('cloud', cloud_mid)\n",
    "                combined_before.coords['cloud_top'] = ('cloud', cloud_top)\n",
    "                combined_before.coords['cloud_depth'] = ('cloud', cloud_depth)\n",
    "        \n",
    "                combined_after = xr.concat(after_arrays, dim='cloud')\n",
    "                combined_after.coords['cloud_length'] = ('cloud', cloud_length)\n",
    "                combined_after.coords['cloud_bottom'] = ('cloud', cloud_bottom)\n",
    "                combined_after.coords['cloud_mid'] = ('cloud', cloud_mid)\n",
    "                combined_after.coords['cloud_top'] = ('cloud', cloud_top)\n",
    "                combined_after.coords['cloud_depth'] = ('cloud', cloud_depth)\n",
    "        \n",
    "                return combined_before, combined_after\n",
    "        \n",
    "    MR_combined_before_bottom, MR_combined_after_bottom = create_combined_xarray(MR_before_bottom_arrays, MR_after_bottom_arrays)\n",
    "    MR_combined_before_mid, MR_combined_after_mid = create_combined_xarray(MR_before_mid_arrays, MR_after_mid_arrays)\n",
    "    MR_combined_before_top, MR_combined_after_top = create_combined_xarray(MR_before_top_arrays, MR_after_top_arrays)\n",
    "    \n",
    "    return MR_combined_before_bottom, MR_combined_before_mid, MR_combined_before_top, MR_combined_after_bottom, MR_combined_after_mid, MR_combined_after_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c20e975-3faa-4a9c-a7e5-02986664eab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we convert times into distances with th efollowing function. It has already been defined in the \"process_LW_BC_data.ipynb\" notebook:\n",
    "def lw_down_clouds_dist_approx(LW_down_clouds, windspeed_avg):\n",
    "    \"\"\"\n",
    "    Converts the time dimension into distance using the average windspeed. This approximation is justified since the focus is not on a few meters of \n",
    "    precision. This average windspeed is enough.\n",
    "    \"\"\"\n",
    "    # Calculate distance from cloud based on time and windspeed\n",
    "    distance_from_cloud = LW_down_clouds.time * windspeed_avg.item()\n",
    "    \n",
    "    # Rename the 'time' dimension to 'distance_from_cloud'\n",
    "    LW_down_clouds = LW_down_clouds.rename({'time': 'distance_from_cloud'})\n",
    "    \n",
    "    # Create a new coordinate 'distance' using the calculated distances\n",
    "    LW_down_clouds.coords['distance'] = ('distance_from_cloud', distance_from_cloud.data)\n",
    "    \n",
    "    # Replace the existing 'time' coordinate with the new 'distance' coordinate\n",
    "    LW_down_clouds = LW_down_clouds.swap_dims({'distance_from_cloud': 'distance'})\n",
    "    \n",
    "    # Add units attribute to the distance coordinate\n",
    "    LW_down_clouds.coords['distance'].attrs['units'] = 'm'\n",
    "    \n",
    "    return LW_down_clouds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9272708f-4ace-4093-8f48-8be9068bee5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 50s, sys: 2.74 s, total: 6min 53s\n",
      "Wall time: 7min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "RH_combined_before_bottom, RH_combined_before_mid, RH_combined_before_top, RH_combined_after_bottom, RH_combined_after_mid, RH_combined_after_top = profiles_1_d_alt(masked_RH, clouds_shallow)\n",
    "dataset = xr.Dataset({\n",
    "    'RH_combined_before_bottom': RH_combined_before_bottom,\n",
    "    'RH_combined_before_mid': RH_combined_before_mid,\n",
    "    'RH_combined_before_top': RH_combined_before_top,\n",
    "    'RH_combined_after_bottom': RH_combined_after_bottom,\n",
    "    'RH_combined_after_mid': RH_combined_after_mid,\n",
    "    'RH_combined_after_top': RH_combined_after_top,\n",
    "})\n",
    "\n",
    "dataset.to_netcdf('./../data/processed_data/1d_anomalies/clouds_diff_shallow.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7bef949e-183e-4d72-95ec-da68ecd0858d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 41s, sys: 1.4 s, total: 2min 42s\n",
      "Wall time: 3min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "RH_combined_before_bottom, RH_combined_before_mid, RH_combined_before_top, RH_combined_after_bottom, RH_combined_after_mid, RH_combined_after_top = profiles_1_d_alt(masked_RH, clouds_deep)\n",
    "dataset = xr.Dataset({\n",
    "    'RH_combined_before_bottom': RH_combined_before_bottom,\n",
    "    'RH_combined_before_mid': RH_combined_before_mid,\n",
    "    'RH_combined_before_top': RH_combined_before_top,\n",
    "    'RH_combined_after_bottom': RH_combined_after_bottom,\n",
    "    'RH_combined_after_mid': RH_combined_after_mid,\n",
    "    'RH_combined_after_top': RH_combined_after_top,\n",
    "})\n",
    "\n",
    "dataset.to_netcdf('./../data/processed_data/1d_anomalies/clouds_diff_deep.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9207af-98bb-4b2f-adce-fa4e2882ad69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "1 Python 3 (based on the module python3/2023.01)",
   "language": "python",
   "name": "python3_2023_01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
